{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from iflow.dataset import gen_cycle_dataset\n",
    "from data.human_robot_interaction_data.read_hh_hr_data import read_data\n",
    "from iflow.dataset.iros_dataset import IROS\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from iflow.dataset import drums_dataset, gen_cycle_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from iflow import model\n",
    "from iflow.trainers import cycle_dynamics_train\n",
    "from iflow.utils.generic import to_torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from iflow.visualization import visualize_vector_field, visualize_trajectories\n",
    "from iflow.test_measures.log_likelihood import cycle_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p, data_q, names, times = read_data('data/human_robot_interaction_data/hh/p1/hand_shake_s1_1.csv')\n",
    "segments = np.load('data/human_robot_interaction_data/hh/segmentation/hand_shake_1.npy')\n",
    "trajs = [data_p[s[0]:s[1], :, :] for s in segments]\n",
    "\n",
    "# downsample\n",
    "stepsize = 1\n",
    "cutoff = 400\n",
    "\n",
    "trajs_downsampled = np.array([a[::stepsize,:,:][:cutoff] for a in trajs])\n",
    "trajs_downsampled.shape\n",
    "trajs = trajs_downsampled.reshape(19,cutoff,26*3)[:,:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trajs.shape)\n",
    "p = -1\n",
    "for i in range(0,10):\n",
    "    plt.plot(-trajs_downsampled[i,:,p,2],trajs_downsampled[i,:,p,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trajs = np.load('data/DRUMS_dataset/Drums.npy')\n",
    "#trajs = np.load('data/IROS_dataset/RShape.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gen_cycle_dataset.GENCYCLE(trajs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "depth = 10\n",
    "## optimization ##\n",
    "lr = 0.001\n",
    "weight_decay = 0.1\n",
    "## training variables ##\n",
    "nr_epochs = 1000\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_layer(dim):\n",
    "    return  model.ResNetCouplingLayer(dim)\n",
    "\n",
    "def create_flow_seq(dim, depth):\n",
    "    chain = []\n",
    "    for i in range(depth):\n",
    "        chain.append(main_layer(dim))\n",
    "        chain.append(model.RandomPermutation(dim))\n",
    "        chain.append(model.LULinear(dim))\n",
    "    chain.append(main_layer(dim))\n",
    "    return model.SequentialFlow(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = data.dim\n",
    "T_period = (2*np.pi)/data.w\n",
    "params = {'batch_size': batch_size, 'shuffle': True}\n",
    "dataloader = DataLoader(data.dataset, **params)\n",
    "\n",
    "lsd = model.LinearLimitCycle(dim, device, dt=data.dt, T_period=T_period)\n",
    "flow = create_flow_seq(dim, depth)\n",
    "iflow = model.ContinuousDynamicFlow(dynamics=lsd, model=flow, dim=dim).to(device)\n",
    "\n",
    "params = list(flow.parameters()) + list(lsd.parameters())\n",
    "optimizer = optim.Adamax(params, lr = lr, weight_decay= weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m dataloader\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mset_step()\n\u001b[1;32m      5\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 6\u001b[0m loss \u001b[39m=\u001b[39m cycle_dynamics_train(iflow, local_x, local_y)\n\u001b[1;32m      7\u001b[0m loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/iflow/trainers/dynamic_flows_train.py:40\u001b[0m, in \u001b[0;36mcycle_dynamics_train\u001b[0;34m(iflow, x, y)\u001b[0m\n\u001b[1;32m     37\u001b[0m x_1, log_det_J_x1 \u001b[39m=\u001b[39m iflow(y1)\n\u001b[1;32m     39\u001b[0m \u001b[39m### Forward Conditioning ###\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m log_p_z1 \u001b[39m=\u001b[39m iflow\u001b[39m.\u001b[39;49mdynamics\u001b[39m.\u001b[39;49mcartesian_cond_log_prob(x_0, x_1, T\u001b[39m=\u001b[39;49mstep)\n\u001b[1;32m     41\u001b[0m log_trj \u001b[39m=\u001b[39m log_p_z1 \u001b[39m+\u001b[39m log_det_J_x1\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     43\u001b[0m \u001b[39m### Stable Point ###\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/iflow/model/dynamics/generic_dynamic.py:270\u001b[0m, in \u001b[0;36mcartesian_cond_log_prob\u001b[0;34m(self, xt0, xt1, T, reverse)\u001b[0m\n\u001b[1;32m    268\u001b[0m     dist_z \u001b[39m=\u001b[39m tdist\u001b[39m.\u001b[39mMultivariateNormal(loc\u001b[39m=\u001b[39m_mu[:,\u001b[39m2\u001b[39m:], scale\u001b[39m=\u001b[39m_var[:,\u001b[39m2\u001b[39m:,\u001b[39m2\u001b[39m:])\n\u001b[1;32m    269\u001b[0m     dists\u001b[39m.\u001b[39mappend(dist_z)\n\u001b[0;32m--> 270\u001b[0m \u001b[39mreturn\u001b[39;00m dists\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/iflow/model/dynamics/generic_dynamic.py:260\u001b[0m, in \u001b[0;36mcartesian_conditional_distribution\u001b[0;34m(self, xti, T, reverse)\u001b[0m\n\u001b[1;32m    257\u001b[0m         _var \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(torch\u001b[39m.\u001b[39mbmm(Ad, _var), Ad) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt\n\u001b[1;32m    259\u001b[0m dists \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 260\u001b[0m dist_r \u001b[39m=\u001b[39m tdist\u001b[39m.\u001b[39mNormal(loc\u001b[39m=\u001b[39m_mu[:,\u001b[39m0\u001b[39m], scale\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39msqrt(_var[:,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]))\n\u001b[1;32m    261\u001b[0m dists\u001b[39m.\u001b[39mappend(dist_r)\n\u001b[1;32m    262\u001b[0m dist_w \u001b[39m=\u001b[39m AngleNormal(loc\u001b[39m=\u001b[39m_mu[:,\u001b[39m1\u001b[39m], scale\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39msqrt(_var[:,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]))\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/iflow/model/dynamics/generic_dynamic.py:174\u001b[0m, in \u001b[0;36mevolve\u001b[0;34m(self, xti, T, reverse, noise)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39m##Evolve\u001b[39;00m\n\u001b[1;32m    172\u001b[0m vel \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvelocity(xt1)\n\u001b[0;32m--> 174\u001b[0m mu_b \u001b[39m=\u001b[39m vel \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt \u001b[39m+\u001b[39m xt1\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m noise \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    176\u001b[0m     var_b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/iflow/model/dynamics/generic_dynamic.py:141\u001b[0m, in \u001b[0;36mLimitCycleDynamicModel.step_forward\u001b[0;34m(self, xt0, noise)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39m##Evolve\u001b[39;00m\n\u001b[1;32m    140\u001b[0m vel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvelocity(xt0)\n\u001b[0;32m--> 141\u001b[0m mu \u001b[39m=\u001b[39m vel \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt \u001b[39m+\u001b[39m xt0\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m noise \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     var_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/iflow/model/dynamics/generic_dynamic.py:141\u001b[0m, in \u001b[0;36mLimitCycleDynamicModel.step_forward\u001b[0;34m(self, xt0, noise)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39m##Evolve\u001b[39;00m\n\u001b[1;32m    140\u001b[0m vel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvelocity(xt0)\n\u001b[0;32m--> 141\u001b[0m mu \u001b[39m=\u001b[39m vel \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt \u001b[39m+\u001b[39m xt0\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m noise \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     var_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvar \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/venv/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:988\u001b[0m, in \u001b[0;36mPyDBFrame.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m# if thread has a suspend flag, we suspend with a busy wait\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[39mif\u001b[39;00m info\u001b[39m.\u001b[39mpydev_state \u001b[39m==\u001b[39m STATE_SUSPEND:\n\u001b[0;32m--> 988\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_wait_suspend(thread, frame, event, arg)\n\u001b[1;32m    989\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrace_dispatch\n\u001b[1;32m    990\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/venv/lib/python3.8/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_frame.py:165\u001b[0m, in \u001b[0;36mPyDBFrame.do_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_wait_suspend\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 165\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mdo_wait_suspend(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/venv/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/iflow/venv/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(nr_epochs):\n",
    "    # Training\n",
    "    for local_x, local_y in dataloader:\n",
    "        dataloader.dataset.set_step()\n",
    "        optimizer.zero_grad()\n",
    "        loss = cycle_dynamics_train(iflow, local_x, local_y)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "    ## Validation ##\n",
    "    if i%10 == 0:\n",
    "        with torch.no_grad():\n",
    "            iflow.eval()\n",
    "\n",
    "            # plotting\n",
    "            out = iflow.generate_trj(torch.from_numpy(data.train_data[0][0][None, :]).float().to(device), data.train_data[0].shape[0])\n",
    "            out = out.detach().cpu().numpy()\n",
    "            plt.plot(out[:,0], out[:,1], 'r')\n",
    "            for t in data.train_data:\n",
    "                plt.plot(t[:,0], t[:,1])\n",
    "            plt.show()\n",
    "\n",
    "            # likelihood\n",
    "            step = 20\n",
    "            trj = data.train_data[0]\n",
    "            trj_x0 = to_torch(trj[:-step,:], device)\n",
    "            trj_x1 = to_torch(trj[step:,:], device)\n",
    "            phase = to_torch(data.train_phase_data[0][:-step], device)\n",
    "            cycle_log_likelihood(trj_x0, trj_x1, phase, step, iflow, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_number = 3\n",
    "val_trj = data.train_data\n",
    "\n",
    "\n",
    "_trajs = np.zeros((0, 2))\n",
    "for trj in val_trj:\n",
    "    _trajs = np.concatenate((_trajs, trj),0)\n",
    "min = _trajs.min(0) - 0.5\n",
    "max = _trajs.max(0) + 0.5\n",
    "\n",
    "n_sample = 100\n",
    "\n",
    "x = np.linspace(min[0], max[0], n_sample)\n",
    "y = np.linspace(min[1], max[1], n_sample)\n",
    "\n",
    "xy = np.meshgrid(x, y)\n",
    "h = np.concatenate(xy[0])\n",
    "v = np.concatenate(xy[1])\n",
    "hv = torch.Tensor(np.stack([h, v]).T).float()\n",
    "if device is not None:\n",
    "    hv = hv.to(device)\n",
    "\n",
    "hv_t1 = iflow.evolve(hv, T=3)\n",
    "hv = hv.detach().cpu().numpy()\n",
    "hv_t1 = hv_t1.detach().cpu().numpy()\n",
    "\n",
    "vel = (hv_t1 - hv)\n",
    "\n",
    "vel_x = np.reshape(vel[:, 0], (n_sample, n_sample))\n",
    "vel_y = np.reshape(vel[:, 1], (n_sample, n_sample))\n",
    "speed = np.sqrt(vel_x ** 2 + vel_y ** 2)\n",
    "speed = speed/np.max(speed)\n",
    "\n",
    "fig = plt.figure(fig_number, figsize=(10, 10))\n",
    "plt.clf()\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.streamplot(xy[0], xy[1], vel_x, vel_y, density=[0.5, 1])\n",
    "for i in range(len(val_trj)):\n",
    "    plt.plot(val_trj[i][:,0], val_trj[i][:,1], 'b')\n",
    "plt.draw()\n",
    "plt.pause(0.05)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d689259aec14598ae7a545a7899819e6e388706210fdad9ff7dfb01827750c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
